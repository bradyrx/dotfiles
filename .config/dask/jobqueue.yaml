jobqueue:
  pbs:
    name: dask-worker

    # Dask worker options
    cores: 36                 # Total number of cores per job
    memory: "100 GB"                # Total amount of memory per job
    processes: 18                # Number of Python processes per job

    interface: ib0             # Network interface to use like eth0 or ib0
    death-timeout: 60           # Number of seconds to wait if a worker can not find a scheduler
    local-directory: /glade/scratch/rbrady/dask_dump       # Location of fast local storage like /scratch or $TMPDIR

    # PBS resource manager options
    queue: regular 
    project: p93300670 
    walltime: '01:00:00'

  slurm:
    name: dask-worker

    # Dask worker options
    cores: 36                 # Total number of cores per job
    memory: "100 GB"                # Total amount of memory per job
    processes: 18                # Number of Python processes per job

    interface: ib0             # Network interface to use like eth0 or ib0
    death-timeout: 60           # Number of seconds to wait if a worker can not find a scheduler
    local-directory: /glade/scratch/rbrady/dask_dump       # Location of fast local storage like /scratch or $TMPDIR
    project: p93300670 
    walltime: '01:00:00'

distributed:
  worker:
    memory:
      target: false  # don't spill to disk 
      spill: false  # don't spill to disk 
      pause: 0.80  # fraction at which we pause worker threads
      terminate: 0.95  # fraction at which we terminate the worker
